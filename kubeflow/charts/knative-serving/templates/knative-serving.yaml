apiVersion: v1
kind: Namespace
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    istio-injection: enabled
    serving.knative.dev/release: v1.9.2
  name: knative-serving
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook.domainmapping.serving.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: domainmapping-webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: webhook.domainmapping.serving.knative.dev
  rules:
  - apiGroups:
    - serving.knative.dev
    apiVersions:
    - v1alpha1
    - v1beta1
    operations:
    - CREATE
    - UPDATE
    resources:
    - domainmappings
    scope: '*'
  sideEffects: None
  timeoutSeconds: 10
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: webhook.istio.networking.internal.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: net-istio-webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: webhook.istio.networking.internal.knative.dev
  objectSelector:
    matchExpressions:
    - key: serving.knative.dev/configuration
      operator: Exists
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook.serving.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: webhook.serving.knative.dev
  rules:
  - apiGroups:
    - autoscaling.internal.knative.dev
    - networking.internal.knative.dev
    - serving.knative.dev
    apiVersions:
    - '*'
    operations:
    - CREATE
    - UPDATE
    resources:
    - metrics
    - podautoscalers
    - certificates
    - ingresses
    - serverlessservices
    - configurations
    - revisions
    - routes
    - services
    scope: '*'
  sideEffects: None
  timeoutSeconds: 10
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: controller
  namespace: knative-serving
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    duck.knative.dev/addressable: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-addressable-resolver
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - routes
  - routes/status
  - services
  - services/status
  verbs:
  - get
  - list
  - watch
---
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      serving.knative.dev/controller: "true"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: knative-serving-admin
---
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      duck.knative.dev/addressable: "true"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: knative-serving-aggregated-addressable-resolver
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/controller: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-core
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  - secrets
  - configmaps
  - endpoints
  - services
  - events
  - serviceaccounts
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - ""
  resources:
  - endpoints/restricted
  verbs:
  - create
- apiGroups:
  - ""
  resources:
  - namespaces/finalizers
  verbs:
  - update
- apiGroups:
  - apps
  resources:
  - deployments
  - deployments/finalizers
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  - customresourcedefinitions/status
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
- apiGroups:
  - serving.knative.dev
  - autoscaling.internal.knative.dev
  - networking.internal.knative.dev
  resources:
  - '*'
  - '*/status'
  - '*/finalizers'
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - deletecollection
  - patch
  - watch
- apiGroups:
  - caching.internal.knative.dev
  resources:
  - images
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/controller: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-istio
rules:
- apiGroups:
  - networking.istio.io
  resources:
  - virtualservices
  - gateways
  - destinationrules
  verbs:
  - get
  - list
  - create
  - update
  - delete
  - patch
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-admin: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-namespaced-admin
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-edit: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-namespaced-edit
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - '*'
  verbs:
  - create
  - update
  - patch
  - delete
- apiGroups:
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    rbac.authorization.k8s.io/aggregate-to-view: "true"
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-view: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-namespaced-view
rules:
- apiGroups:
  - serving.knative.dev
  - networking.internal.knative.dev
  - autoscaling.internal.knative.dev
  - caching.internal.knative.dev
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    duck.knative.dev/podspecable: "true"
    serving.knative.dev/release: v1.9.2
  name: knative-serving-podspecable-binding
rules:
- apiGroups:
  - serving.knative.dev
  resources:
  - configurations
  - services
  verbs:
  - list
  - watch
  - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: knative-serving-controller-addressable-resolver
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: knative-serving-aggregated-addressable-resolver
subjects:
- kind: ServiceAccount
  name: controller
  namespace: knative-serving
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: knative-serving-controller-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: knative-serving-admin
subjects:
- kind: ServiceAccount
  name: controller
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # The Revision ContainerConcurrency field specifies the maximum number
    # of requests the Container can handle at once. Container concurrency
    # target percentage is how much of that maximum to use in a stable
    # state. E.g. if a Revision specifies ContainerConcurrency of 10, then
    # the Autoscaler will try to maintain 7 concurrent connections per pod
    # on average.
    # Note: this limit will be applied to container concurrency set at every
    # level (ConfigMap, Revision Spec or Annotation).
    # For legacy and backwards compatibility reasons, this value also accepts
    # fractional values in (0, 1] interval (i.e. 0.7 ⇒ 70%).
    # Thus minimal percentage value must be greater than 1.0, or it will be
    # treated as a fraction.
    # NOTE: that this value does not affect actual number of concurrent requests
    #       the user container may receive, but only the average number of requests
    #       that the revision pods will receive.
    container-concurrency-target-percentage: "70"

    # The container concurrency target default is what the Autoscaler will
    # try to maintain when concurrency is used as the scaling metric for the
    # Revision and the Revision specifies unlimited concurrency.
    # When revision explicitly specifies container concurrency, that value
    # will be used as a scaling target for autoscaler.
    # When specifying unlimited concurrency, the autoscaler will
    # horizontally scale the application based on this target concurrency.
    # This is what we call "soft limit" in the documentation, i.e. it only
    # affects number of pods and does not affect the number of requests
    # individual pod processes.
    # The value must be a positive number such that the value multiplied
    # by container-concurrency-target-percentage is greater than 0.01.
    # NOTE: that this value will be adjusted by application of
    #       container-concurrency-target-percentage, i.e. by default
    #       the system will target on average 70 concurrent requests
    #       per revision pod.
    # NOTE: Only one metric can be used for autoscaling a Revision.
    container-concurrency-target-default: "100"

    # The requests per second (RPS) target default is what the Autoscaler will
    # try to maintain when RPS is used as the scaling metric for a Revision and
    # the Revision specifies unlimited RPS. Even when specifying unlimited RPS,
    # the autoscaler will horizontally scale the application based on this
    # target RPS.
    # Must be greater than 1.0.
    # NOTE: Only one metric can be used for autoscaling a Revision.
    requests-per-second-target-default: "200"

    # The target burst capacity specifies the size of burst in concurrent
    # requests that the system operator expects the system will receive.
    # Autoscaler will try to protect the system from queueing by introducing
    # Activator in the request path if the current spare capacity of the
    # service is less than this setting.
    # If this setting is 0, then Activator will be in the request path only
    # when the revision is scaled to 0.
    # If this setting is > 0 and container-concurrency-target-percentage is
    # 100% or 1.0, then activator will always be in the request path.
    # -1 denotes unlimited target-burst-capacity and activator will always
    # be in the request path.
    # Other negative values are invalid.
    target-burst-capacity: "200"

    # When operating in a stable mode, the autoscaler operates on the
    # average concurrency over the stable window.
    # Stable window must be in whole seconds.
    stable-window: "60s"

    # When observed average concurrency during the panic window reaches
    # panic-threshold-percentage the target concurrency, the autoscaler
    # enters panic mode. When operating in panic mode, the autoscaler
    # scales on the average concurrency over the panic window which is
    # panic-window-percentage of the stable-window.
    # Must be in the [1, 100] range.
    # When computing the panic window it will be rounded to the closest
    # whole second, at least 1s.
    panic-window-percentage: "10.0"

    # The percentage of the container concurrency target at which to
    # enter panic mode when reached within the panic window.
    panic-threshold-percentage: "200.0"

    # Max scale up rate limits the rate at which the autoscaler will
    # increase pod count. It is the maximum ratio of desired pods versus
    # observed pods.
    # Cannot be less or equal to 1.
    # I.e with value of 2.0 the number of pods can at most go N to 2N
    # over single Autoscaler period (2s), but at least N to
    # N+1, if Autoscaler needs to scale up.
    max-scale-up-rate: "1000.0"

    # Max scale down rate limits the rate at which the autoscaler will
    # decrease pod count. It is the maximum ratio of observed pods versus
    # desired pods.
    # Cannot be less or equal to 1.
    # I.e. with value of 2.0 the number of pods can at most go N to N/2
    # over single Autoscaler evaluation period (2s), but at
    # least N to N-1, if Autoscaler needs to scale down.
    max-scale-down-rate: "2.0"

    # Scale to zero feature flag.
    enable-scale-to-zero: "true"

    # Scale to zero grace period is the time an inactive revision is left
    # running before it is scaled to zero (must be positive, but recommended
    # at least a few seconds if running with mesh networking).
    # This is the upper limit and is provided not to enforce timeout after
    # the revision stopped receiving requests for stable window, but to
    # ensure network reprogramming to put activator in the path has completed.
    # If the system determines that a shorter period is satisfactory,
    # then the system will only wait that amount of time before scaling to 0.
    # NOTE: this period might actually be 0, if activator has been
    # in the request path sufficiently long.
    # If there is necessity for the last pod to linger longer use
    # scale-to-zero-pod-retention-period flag.
    scale-to-zero-grace-period: "30s"

    # Scale to zero pod retention period defines the minimum amount
    # of time the last pod will remain after Autoscaler has decided to
    # scale to zero.
    # This flag is for the situations where the pod startup is very expensive
    # and the traffic is bursty (requiring smaller windows for fast action),
    # but patchy.
    # The larger of this flag and `scale-to-zero-grace-period` will effectively
    # determine how the last pod will hang around.
    scale-to-zero-pod-retention-period: "0s"

    # pod-autoscaler-class specifies the default pod autoscaler class
    # that should be used if none is specified. If omitted,
    # the Knative Pod Autoscaler (KPA) is used by default.
    pod-autoscaler-class: "kpa.autoscaling.knative.dev"

    # The capacity of a single activator task.
    # The `unit` is one concurrent request proxied by the activator.
    # activator-capacity must be at least 1.
    # This value is used for computation of the Activator subset size.
    # See the algorithm here: http://bit.ly/38XiCZ3.
    # TODO(vagababov): tune after actual benchmarking.
    activator-capacity: "100.0"

    # initial-scale is the cluster-wide default value for the initial target
    # scale of a revision after creation, unless overridden by the
    # "autoscaling.knative.dev/initialScale" annotation.
    # This value must be greater than 0 unless allow-zero-initial-scale is true.
    initial-scale: "1"

    # allow-zero-initial-scale controls whether either the cluster-wide initial-scale flag,
    # or the "autoscaling.knative.dev/initialScale" annotation, can be set to 0.
    allow-zero-initial-scale: "false"

    # min-scale is the cluster-wide default value for the min scale of a revision,
    # unless overridden by the "autoscaling.knative.dev/minScale" annotation.
    min-scale: "0"

    # max-scale is the cluster-wide default value for the max scale of a revision,
    # unless overridden by the "autoscaling.knative.dev/maxScale" annotation.
    # If set to 0, the revision has no maximum scale.
    max-scale: "0"

    # scale-down-delay is the amount of time that must pass at reduced
    # concurrency before a scale down decision is applied. This can be useful,
    # for example, to maintain replica count and avoid a cold start penalty if
    # more requests come in within the scale down delay period.
    # The default, 0s, imposes no delay at all.
    scale-down-delay: "0s"

    # max-scale-limit sets the maximum permitted value for the max scale of a revision.
    # When this is set to a positive value, a revision with a maxScale above that value
    # (including a maxScale of "0" = unlimited) is disallowed.
    # A value of zero (the default) allows any limit, including unlimited.
    max-scale-limit: "0"
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: 16af78ce
  labels:
    app.kubernetes.io/component: autoscaler
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-autoscaler
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # revision-timeout-seconds contains the default number of
    # seconds to use for the revision's per-request timeout, if
    # none is specified.
    revision-timeout-seconds: "300"  # 5 minutes

    # max-revision-timeout-seconds contains the maximum number of
    # seconds that can be used for revision-timeout-seconds.
    # This value must be greater than or equal to revision-timeout-seconds.
    # If omitted, the system default is used (600 seconds).
    #
    # If this value is increased, the activator's terminationGraceTimeSeconds
    # should also be increased to prevent in-flight requests being disrupted.
    max-revision-timeout-seconds: "600"  # 10 minutes

    # revision-cpu-request contains the cpu allocation to assign
    # to revisions by default.  If omitted, no value is specified
    # and the system default is used.
    # Below is an example of setting revision-cpu-request.
    # By default, it is not set by Knative.
    revision-cpu-request: "400m"  # 0.4 of a CPU (aka 400 milli-CPU)

    # revision-memory-request contains the memory allocation to assign
    # to revisions by default.  If omitted, no value is specified
    # and the system default is used.
    # Below is an example of setting revision-memory-request.
    # By default, it is not set by Knative.
    revision-memory-request: "100M"  # 100 megabytes of memory

    # revision-ephemeral-storage-request contains the ephemeral storage
    # allocation to assign to revisions by default.  If omitted, no value is
    # specified and the system default is used.
    revision-ephemeral-storage-request: "500M"  # 500 megabytes of storage

    # revision-cpu-limit contains the cpu allocation to limit
    # revisions to by default.  If omitted, no value is specified
    # and the system default is used.
    # Below is an example of setting revision-cpu-limit.
    # By default, it is not set by Knative.
    revision-cpu-limit: "1000m"  # 1 CPU (aka 1000 milli-CPU)

    # revision-memory-limit contains the memory allocation to limit
    # revisions to by default.  If omitted, no value is specified
    # and the system default is used.
    # Below is an example of setting revision-memory-limit.
    # By default, it is not set by Knative.
    revision-memory-limit: "200M"  # 200 megabytes of memory

    # revision-ephemeral-storage-limit contains the ephemeral storage
    # allocation to limit revisions to by default.  If omitted, no value is
    # specified and the system default is used.
    revision-ephemeral-storage-limit: "750M"  # 750 megabytes of storage

    # container-name-template contains a template for the default
    # container name, if none is specified.  This field supports
    # Go templating and is supplied with the ObjectMeta of the
    # enclosing Service or Configuration, so values such as
    # {{.Name}} are also valid.
    container-name-template: "user-container"

    # init-container-name-template contains a template for the default
    # init container name, if none is specified.  This field supports
    # Go templating and is supplied with the ObjectMeta of the
    # enclosing Service or Configuration, so values such as
    # {{.Name}} are also valid.
    init-container-name-template: "init-container"

    # container-concurrency specifies the maximum number
    # of requests the Container can handle at once, and requests
    # above this threshold are queued.  Setting a value of zero
    # disables this throttling and lets through as many requests as
    # the pod receives.
    container-concurrency: "0"

    # The container concurrency max limit is an operator setting ensuring that
    # the individual revisions cannot have arbitrary large concurrency
    # values, or autoscaling targets. `container-concurrency` default setting
    # must be at or below this value.
    #
    # Must be greater than 1.
    #
    # Note: even with this set, a user can choose a containerConcurrency
    # of 0 (i.e. unbounded) unless allow-container-concurrency-zero is
    # set to "false".
    container-concurrency-max-limit: "1000"

    # allow-container-concurrency-zero controls whether users can
    # specify 0 (i.e. unbounded) for containerConcurrency.
    allow-container-concurrency-zero: "true"

    # enable-service-links specifies the default value used for the
    # enableServiceLinks field of the PodSpec, when it is omitted by the user.
    # See: https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#accessing-the-service
    #
    # This is a tri-state flag with possible values of (true|false|default).
    #
    # In environments with large number of services it is suggested
    # to set this value to `false`.
    # See https://github.com/knative/serving/issues/8498.
    enable-service-links: "false"
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: a0feb4c6
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-defaults
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |-
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # List of repositories for which tag to digest resolving should be skipped
    registries-skipping-tag-resolving: "kind.local,ko.local,dev.local"

    # Maximum time allowed for an image's digests to be resolved.
    digest-resolution-timeout: "10s"

    # Duration we wait for the deployment to be ready before considering it failed.
    progress-deadline: "600s"

    # Sets the queue proxy's CPU request.
    # If omitted, a default value (currently "25m"), is used.
    queue-sidecar-cpu-request: "25m"

    # Sets the queue proxy's CPU limit.
    # If omitted, no value is specified and the system default is used.
    queue-sidecar-cpu-limit: "1000m"

    # Sets the queue proxy's memory request.
    # If omitted, no value is specified and the system default is used.
    queue-sidecar-memory-request: "400Mi"

    # Sets the queue proxy's memory limit.
    # If omitted, no value is specified and the system default is used.
    queue-sidecar-memory-limit: "800Mi"

    # Sets the queue proxy's ephemeral storage request.
    # If omitted, no value is specified and the system default is used.
    queue-sidecar-ephemeral-storage-request: "512Mi"

    # Sets the queue proxy's ephemeral storage limit.
    # If omitted, no value is specified and the system default is used.
    queue-sidecar-ephemeral-storage-limit: "1024Mi"

    # The freezer service endpoint that queue-proxy calls when its traffic drops to zero or
    # scales up from zero.
    #
    # Freezer service is available at: https://github.com/knative-sandbox/container-freezer
    # or users may write their own service.
    #
    # The value will need to include both the host and the port that will be accessed.
    # For the host, $HOST_IP can be passed, and the appropriate host IP value will be swapped
    # in at runtime, which will enable the freezer daemonset to be reachable via the node IP.
    #
    # As an example:
    #     concurrency-state-endpoint: "http://$HOST_IP:9696"
    #
    # If not set, queue proxy takes no action (this is the default behavior).
    #
    # When enabled, a serviceAccountToken will be mounted to queue-proxy using
    # a projected volume. This requires the Service Account Token Volume Projection feature
    # to be enabled. For details, see this link:
    # https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection
    #
    # NOTE THAT THIS IS AN EXPERIMENTAL / ALPHA FEATURE
    concurrency-state-endpoint: ""
  progressDeadline: 600s
  queueSidecarImage: {{ .Values.knativeServingQueueImage }}:{{ .Values.knativeVersion }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: dd7ee769
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-deployment
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # Default value for domain.
    # Although it will match all routes, it is the least-specific rule so it
    # will only be used if no other domain matches.
    example.com: |

    # These are example settings of domain.
    # example.org will be used for routes having app=nonprofit.
    example.org: |
      selector:
        app: nonprofit

    # Routes having the cluster domain suffix (by default 'svc.cluster.local')
    # will not be exposed through Ingress. You can define your own label
    # selector to assign that domain suffix to your Route here, or you can set
    # the label
    #    "networking.knative.dev/visibility=cluster-local"
    # to achieve the same effect.  This shows how to make routes having
    # the label app=secret only exposed to the local cluster.
    svc.cluster.local: |
      selector:
        app: secret
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: 81552d0b
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-domain
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |-
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.

    # Indicates whether multi container support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#multi-containers
    multi-container: "enabled"

    # Indicates whether Kubernetes affinity support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-node-affinity
    kubernetes.podspec-affinity: "disabled"

    # Indicates whether Kubernetes hostAliases support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-host-aliases
    kubernetes.podspec-hostaliases: "disabled"

    # Indicates whether Kubernetes nodeSelector support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-node-selector
    kubernetes.podspec-nodeselector: "disabled"

    # Indicates whether Kubernetes tolerations support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-toleration
    kubernetes.podspec-tolerations: "disabled"

    # Indicates whether Kubernetes FieldRef support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-fieldref
    kubernetes.podspec-fieldref: "disabled"

    # Indicates whether Kubernetes RuntimeClassName support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-runtime-class
    kubernetes.podspec-runtimeclassname: "disabled"

    # This feature allows end-users to set a subset of fields on the Pod's SecurityContext
    #
    # When set to "enabled" or "allowed" it allows the following
    # PodSecurityContext properties:
    # - FSGroup
    # - RunAsGroup
    # - RunAsNonRoot
    # - SupplementalGroups
    # - RunAsUser
    #
    # This feature flag should be used with caution as the PodSecurityContext
    # properties may have a side-effect on non-user sidecar containers that come
    # from Knative or your service mesh
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-security-context
    kubernetes.podspec-securitycontext: "disabled"

    # Indicates whether Kubernetes PriorityClassName support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-priority-class-name
    kubernetes.podspec-priorityclassname: "disabled"

    # Indicates whether Kubernetes SchedulerName support is enabled
    #
    # WARNING: Cannot safely be disabled once enabled.
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-scheduler-name
    kubernetes.podspec-schedulername: "disabled"

    # This feature flag allows end-users to add a subset of capabilities on the Pod's SecurityContext.
    #
    # When set to "enabled" or "allowed" it allows capabilities to be added to the container.
    # For a list of possible capabilities, see https://man7.org/linux/man-pages/man7/capabilities.7.html
    kubernetes.containerspec-addcapabilities: "disabled"

    # This feature validates PodSpecs from the validating webhook
    # against the K8s API Server.
    #
    # When "enabled", the server will always run the extra validation.
    # When "allowed", the server will not run the dry-run validation by default.
    #   However, clients may enable the behavior on an individual Service by
    #   attaching the following metadata annotation: "features.knative.dev/podspec-dryrun":"enabled".
    # See: https://knative.dev/docs/serving/feature-flags/#kubernetes-dry-run
    kubernetes.podspec-dryrun: "allowed"

    # Controls whether tag header based routing feature are enabled or not.
    # 1. Enabled: enabling tag header based routing
    # 2. Disabled: disabling tag header based routing
    # See: https://knative.dev/docs/serving/feature-flags/#tag-header-based-routing
    tag-header-based-routing: "disabled"

    # Controls whether http2 auto-detection should be enabled or not.
    # 1. Enabled: http2 connection will be attempted via upgrade.
    # 2. Disabled: http2 connection will only be attempted when port name is set to "h2c".
    autodetect-http2: "disabled"

    # Controls whether volume support for EmptyDir is enabled or not.
    # 1. Enabled: enabling EmptyDir volume support
    # 2. Disabled: disabling EmptyDir volume support
    kubernetes.podspec-volumes-emptydir: "disabled"

    # Controls whether init containers support is enabled or not.
    # 1. Enabled: enabling init containers support
    # 2. Disabled: disabling init containers support
    kubernetes.podspec-init-containers: "disabled"

    # Controls whether persistent volume claim support is enabled or not.
    # 1. Enabled: enabling persistent volume claim support
    # 2. Disabled: disabling persistent volume claim support
    kubernetes.podspec-persistent-volume-claim: "disabled"

    # Controls whether write access for persistent volumes is enabled or not.
    # 1. Enabled: enabling write access for persistent volumes
    # 2. Disabled: disabling write access for persistent volumes
    kubernetes.podspec-persistent-volume-write: "disabled"
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: d9e300ba
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-features
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
    ################################
    #                              #
    #    EXAMPLE CONFIGURATION     #
    #                              #
    ################################

    # This block is not actually functional configuration,
    # but serves to illustrate the available configuration
    # options and document them in a way that is accessible
    # to users that `kubectl edit` this config map.
    #
    # These sample configuration options may be copied out of
    # this example block and unindented to be in the data block
    # to actually change the configuration.


    # ---------------------------------------
    # Garbage Collector Settings
    # ---------------------------------------
    #
    # Active
    #   * Revisions which are referenced by a Route are considered active.
    #   * Individual revisions may be marked with the annotation
    #      "serving.knative.dev/no-gc":"true" to be permanently considered active.
    #   * Active revisions are not considered for GC.
    # Retention
    #   * Revisions are retained if they are any of the following:
    #       1. Active
    #       2. Were created within "retain-since-create-time"
    #       3. Were last referenced by a route within
    #           "retain-since-last-active-time"
    #       4. There are fewer than "min-non-active-revisions"
    #     If none of these conditions are met, or if the count of revisions exceed
    #      "max-non-active-revisions", they will be deleted by GC.
    #     The special value "disabled" may be used to turn off these limits.
    #
    # Example config to immediately collect any inactive revision:
    #    min-non-active-revisions: "0"
    #    retain-since-create-time: "disabled"
    #    retain-since-last-active-time: "disabled"
    #
    # Example config to always keep around the last ten non-active revisions:
    #     retain-since-create-time: "disabled"
    #     retain-since-last-active-time: "disabled"
    #     max-non-active-revisions: "10"
    #
    # Example config to disable all GC:
    #     retain-since-create-time: "disabled"
    #     retain-since-last-active-time: "disabled"
    #     max-non-active-revisions: "disabled"
    #
    # Example config to keep recently deployed or active revisions,
    # always maintain the last two in case of rollback, and prevent
    # burst activity from exploding the count of old revisions:
    #      retain-since-create-time: "48h"
    #      retain-since-last-active-time: "15h"
    #      min-non-active-revisions: "2"
    #      max-non-active-revisions: "1000"

    # Duration since creation before considering a revision for GC or "disabled".
    retain-since-create-time: "48h"

    # Duration since active before considering a revision for GC or "disabled".
    retain-since-last-active-time: "15h"

    # Minimum number of non-active revisions to retain.
    min-non-active-revisions: "20"

    # Maximum number of non-active revisions to retain
    # or "disabled" to disable any maximum limit.
    max-non-active-revisions: "1000"
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: 51b4d68a
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-gc
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-istio.txt" | indent 4 }}
  gateway.kubeflow.kubeflow-gateway: istio-ingressgateway.istio-system.svc.cluster.local
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: config-istio
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-leader-election.txt" | indent 4 }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: f4b71f57
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-leader-election
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-logging.txt" | indent 4 }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: be93ff10
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-logging
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-network.txt" | indent 4 }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: 6e2033e0
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-network
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-observability.txt" | indent 4 }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: fed4756e
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-observability
  namespace: knative-serving
---
apiVersion: v1
data:
  _example: |
{{ .Files.Get "config-examples/config-tracing.txt" | indent 4 }}
kind: ConfigMap
metadata:
  annotations:
    knative.dev/example-checksum: "26614636"
  labels:
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config-tracing
  namespace: knative-serving
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: domainmapping-webhook-certs
  namespace: knative-serving
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: net-istio-webhook-certs
  namespace: knative-serving
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook-certs
  namespace: knative-serving
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    experimental.istio.io/disable-gateway-port-translation: "true"
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: knative-local-gateway
  namespace: istio-system
spec:
  ports:
  - name: http2
    port: 80
    targetPort: 8081
  selector:
    app: cluster-local-gateway
    istio: cluster-local-gateway
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: activator
    app.kubernetes.io/component: activator
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: activator-service
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  - name: http
    port: 80
    targetPort: 8012
  - name: http2
    port: 81
    targetPort: 8013
  selector:
    app: activator
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: autoscaler
    app.kubernetes.io/component: autoscaler
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: autoscaler
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  - name: http
    port: 8080
    targetPort: 8080
  selector:
    app: autoscaler
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: controller
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: controller
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  selector:
    app: controller
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    role: domainmapping-webhook
    serving.knative.dev/release: v1.9.2
  name: domainmapping-webhook
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  - name: https-webhook
    port: 443
    targetPort: 8443
  selector:
    role: domainmapping-webhook
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    role: net-istio-webhook
    serving.knative.dev/release: v1.9.2
  name: net-istio-webhook
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  - name: https-webhook
    port: 443
    targetPort: 8443
  selector:
    app: net-istio-webhook
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    role: webhook
    serving.knative.dev/release: v1.9.2
  name: webhook
  namespace: knative-serving
spec:
  ports:
  - name: http-metrics
    port: 9090
    targetPort: 9090
  - name: http-profiling
    port: 8008
    targetPort: 8008
  - name: https-webhook
    port: 443
    targetPort: 8443
  selector:
    role: webhook
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: activator
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: activator
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: activator
      role: activator
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: activator
        app.kubernetes.io/component: activator
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        role: activator
        serving.knative.dev/release: v1.9.2
    spec:
      containers:
      - env:
        - name: GOGC
          value: "500"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/internal/serving
        image: {{ .Values.knativeServingActivatorImage }}:{{ .Values.knativeVersion }}
        livenessProbe:
          failureThreshold: 12
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: activator
            port: 8012
          initialDelaySeconds: 15
          periodSeconds: 10
        name: activator
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        - containerPort: 8012
          name: http1
        - containerPort: 8013
          name: h2c
        readinessProbe:
          failureThreshold: 5
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: activator
            port: 8012
          periodSeconds: 5
        resources:
          limits:
            cpu: 1000m
            memory: 600Mi
          requests:
            cpu: 300m
            memory: 60Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
      terminationGracePeriodSeconds: 600
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: autoscaler
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: autoscaler
  namespace: knative-serving
spec:
  replicas: 1
  selector:
    matchLabels:
      app: autoscaler
  strategy:
    rollingUpdate:
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: autoscaler
        app.kubernetes.io/component: autoscaler
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        serving.knative.dev/release: v1.9.2
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: autoscaler
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: {{ .Values.knativeServingAutoscalerImage }}:{{ .Values.knativeVersion }}
        livenessProbe:
          failureThreshold: 6
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: autoscaler
            port: 8080
        name: autoscaler
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        - containerPort: 8080
          name: websocket
        readinessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: autoscaler
            port: 8080
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: controller
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: controller
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        sidecar.istio.io/inject: "true"
      labels:
        app: controller
        app.kubernetes.io/component: controller
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        serving.knative.dev/release: v1.9.2
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: controller
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/internal/serving
        image: {{ .Values.knativeServingControllerImage }}:{{ .Values.knativeVersion }}
        name: controller
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 1000m
            memory: 1000Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: domain-mapping
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: domain-mapping
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        sidecar.istio.io/inject: "true"
      labels:
        app: domain-mapping
        app.kubernetes.io/component: domain-mapping
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        serving.knative.dev/release: v1.9.2
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: domain-mapping
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: {{ .Values.knativeServingDomainMappingImage }}:{{ .Values.knativeVersion }}
        name: domain-mapping
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 300m
            memory: 400Mi
          requests:
            cpu: 30m
            memory: 40Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: domainmapping-webhook
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: domainmapping-webhook
      role: domainmapping-webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: domainmapping-webhook
        app.kubernetes.io/component: domain-mapping
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        role: domainmapping-webhook
        serving.knative.dev/release: v1.9.2
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: domainmapping-webhook
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: WEBHOOK_PORT
          value: "8443"
        - name: METRICS_DOMAIN
          value: knative.dev/serving
        image: {{ .Values.knativeServingDomainMappingWebhookImage }}:{{ .Values.knativeVersion }}
        livenessProbe:
          failureThreshold: 6
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: webhook
            port: 8443
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 1
        name: domainmapping-webhook
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        - containerPort: 8443
          name: https-webhook
        readinessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: webhook
            port: 8443
            scheme: HTTPS
          periodSeconds: 1
        resources:
          limits:
            cpu: 500m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
      terminationGracePeriodSeconds: 300
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: net-istio-controller
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: net-istio-controller
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        sidecar.istio.io/inject: "true"
      labels:
        app: net-istio-controller
        app.kubernetes.io/component: net-istio
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        serving.knative.dev/release: v1.9.2
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/net-istio
        image: {{ .Values.knativeNetControllerImage }}:v1.9.2
        name: controller
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        resources:
          limits:
            cpu: 300m
            memory: 400Mi
          requests:
            cpu: 30m
            memory: 40Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: net-istio-webhook
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: net-istio-webhook
      role: net-istio-webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: net-istio-webhook
        app.kubernetes.io/component: net-istio
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        role: net-istio-webhook
        serving.knative.dev/release: v1.9.2
    spec:
      containers:
      - env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: METRICS_DOMAIN
          value: knative.dev/net-istio
        - name: WEBHOOK_NAME
          value: net-istio-webhook
        image: {{ .Values.knativeNetWebhookImage }}:v1.9.2
        name: webhook
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        - containerPort: 8443
          name: https-webhook
        resources:
          limits:
            cpu: 200m
            memory: 200Mi
          requests:
            cpu: 20m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
      serviceAccountName: controller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook
  namespace: knative-serving
spec:
  selector:
    matchLabels:
      app: webhook
      role: webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
        sidecar.istio.io/inject: "true"
      labels:
        app: webhook
        app.kubernetes.io/component: webhook
        app.kubernetes.io/name: knative-serving
        app.kubernetes.io/version: 1.9.2
        role: webhook
        serving.knative.dev/release: v1.9.2
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: webhook
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: config-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: config-observability
        - name: WEBHOOK_NAME
          value: webhook
        - name: WEBHOOK_PORT
          value: "8443"
        - name: METRICS_DOMAIN
          value: knative.dev/internal/serving
        image: {{ .Values.knativeServingWebhookImage }}:{{ .Values.knativeVersion }}
        livenessProbe:
          failureThreshold: 6
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: webhook
            port: 8443
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 1
        name: webhook
        ports:
        - containerPort: 9090
          name: metrics
        - containerPort: 8008
          name: profiling
        - containerPort: 8443
          name: https-webhook
        readinessProbe:
          httpGet:
            httpHeaders:
            - name: k-kubelet-probe
              value: webhook
            port: 8443
            scheme: HTTPS
          periodSeconds: 1
        resources:
          limits:
            cpu: 500m
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - all
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      serviceAccountName: controller
      terminationGracePeriodSeconds: 300
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: activator
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: activator-pdb
  namespace: knative-serving
spec:
  minAvailable: 80%
  selector:
    matchLabels:
      app: activator
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook-pdb
  namespace: knative-serving
spec:
  minAvailable: 80%
  selector:
    matchLabels:
      app: webhook
---
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  labels:
    app.kubernetes.io/component: activator
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: activator
  namespace: knative-serving
spec:
  maxReplicas: 20
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 100
        type: Utilization
    type: Resource
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: activator
---
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: webhook
  namespace: knative-serving
spec:
  maxReplicas: 5
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 100
        type: Utilization
    type: Resource
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webhook
---
apiVersion: caching.internal.knative.dev/v1alpha1
kind: Image
metadata:
  labels:
    app.kubernetes.io/component: queue-proxy
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: queue-proxy
  namespace: knative-serving
spec:
  image: {{ .Values.knativeServingQueueImage }}:{{ .Values.knativeVersion }}
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: knative
  namespace: knative-serving
spec:
  host: '*.knative-serving.svc.cluster.local'
  trafficPolicy:
    tls:
      mode: ISTIO_MUTUAL
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: knative-local-gateway
  namespace: knative-serving
spec:
  selector:
    app: cluster-local-gateway
    istio: cluster-local-gateway
  servers:
  - hosts:
    - '*'
    port:
      name: http
      number: 8081
      protocol: HTTP
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: activator-service
  namespace: knative-serving
spec:
  action: ALLOW
  rules:
  - {}
  selector:
    matchLabels:
      app: activator
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: autoscaler
  namespace: knative-serving
spec:
  action: ALLOW
  rules:
  - {}
  selector:
    matchLabels:
      app: autoscaler
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: controller
  namespace: knative-serving
spec:
  action: ALLOW
  rules:
  - {}
  selector:
    matchLabels:
      app: controller
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: istio-webhook
  namespace: knative-serving
spec:
  action: ALLOW
  rules:
  - {}
  selector:
    matchLabels:
      app: net-istio-webhook
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: webhook
  namespace: knative-serving
spec:
  action: ALLOW
  rules:
  - {}
  selector:
    matchLabels:
      role: webhook
---
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: domainmapping-webhook
  namespace: knative-serving
spec:
  portLevelMtls:
    "8443":
      mode: PERMISSIVE
  selector:
    matchLabels:
      app: domainmapping-webhook
---
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: net-istio-webhook
  namespace: knative-serving
spec:
  portLevelMtls:
    "8443":
      mode: PERMISSIVE
  selector:
    matchLabels:
      app: net-istio-webhook
---
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: webhook
  namespace: knative-serving
spec:
  portLevelMtls:
    "8443":
      mode: PERMISSIVE
  selector:
    matchLabels:
      app: webhook
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: net-istio
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    networking.knative.dev/ingress-provider: istio
    serving.knative.dev/release: v1.9.2
  name: config.webhook.istio.networking.internal.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: net-istio-webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: config.webhook.istio.networking.internal.knative.dev
  namespaceSelector:
    matchExpressions:
    - key: serving.knative.dev/release
      operator: Exists
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: config.webhook.serving.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: config.webhook.serving.knative.dev
  namespaceSelector:
    matchExpressions:
    - key: serving.knative.dev/release
      operator: Exists
  sideEffects: None
  timeoutSeconds: 10
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: domain-mapping
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: validation.webhook.domainmapping.serving.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: domainmapping-webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: validation.webhook.domainmapping.serving.knative.dev
  rules:
  - apiGroups:
    - serving.knative.dev
    apiVersions:
    - v1alpha1
    - v1beta1
    operations:
    - CREATE
    - UPDATE
    - DELETE
    resources:
    - domainmappings
    scope: '*'
  sideEffects: None
  timeoutSeconds: 10
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: webhook
    app.kubernetes.io/name: knative-serving
    app.kubernetes.io/version: 1.9.2
    serving.knative.dev/release: v1.9.2
  name: validation.webhook.serving.knative.dev
webhooks:
- admissionReviewVersions:
  - v1
  - v1beta1
  clientConfig:
    service:
      name: webhook
      namespace: knative-serving
  failurePolicy: Fail
  name: validation.webhook.serving.knative.dev
  rules:
  - apiGroups:
    - autoscaling.internal.knative.dev
    - networking.internal.knative.dev
    - serving.knative.dev
    apiVersions:
    - '*'
    operations:
    - CREATE
    - UPDATE
    - DELETE
    resources:
    - metrics
    - podautoscalers
    - certificates
    - ingresses
    - serverlessservices
    - configurations
    - revisions
    - routes
    - services
    scope: '*'
  sideEffects: None
  timeoutSeconds: 10
