apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: helm-post-install-job
    app.kubernetes.io/component: helm-post-install-job
  name: helm-post-install-job
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: helm-post-install-job-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubeflow-admin
subjects:
- kind: ServiceAccount
  name: helm-post-install-job
  namespace: kubeflow
---
apiVersion: batch/v1
kind: Job
metadata:
  name: kubeflow-post-install-job
  namespace: kubeflow
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "99"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    metadata:
      name: kubeflow-post-install-job
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      serviceAccountName: helm-post-install-job
      restartPolicy: Never
      containers:
      - name: wait-client
        image: {{ .Values.kubectlImage }}
        command: ["/bin/sh", "-c"]
        # wait istio ready and 
        # restart kubeflow components to apply istio sidecar injection
        # ignore not installed resources
        args:
        - |
          kubectl -n istio-system wait --timeout=15m0s --for=condition=ready pod -l app=authservice
          kubectl -n istio-system wait --timeout=15m0s --for=condition=ready pod -l app=istio-ingressgateway
          kubectl -n istio-system wait --timeout=15m0s --for=condition=ready pod -l app=istiod
          
          echo "will automatically restart all components to try if istio injection will take place..."
          kubectl -n kubeflow rollout restart deploy mysql || true
          kubectl -n kubeflow rollout restart deploy minio || true
          kubectl -n kubeflow rollout restart deploy cache-server || true
          kubectl -n kubeflow rollout restart deploy metadata-grpc-deployment  || true
          kubectl -n kubeflow rollout restart deploy metadata-writer  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline-persistenceagent  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline-scheduledworkflow  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline-ui  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline-viewer-crd  || true
          kubectl -n kubeflow rollout restart deploy ml-pipeline-visualizationserver  || true
          kubectl -n kubeflow rollout restart deploy workflow-controller  || true
          kubectl -n kubeflow rollout restart deploy centraldashboard  || true
          echo "kubeflow componets restarted."

---
apiVersion: batch/v1
kind: Job
metadata:
  name: kubeflow-pre-delete-job
  namespace: kubeflow
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": pre-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    metadata:
      name: kubeflow-pre-delete-job
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      serviceAccountName: helm-post-install-job
      restartPolicy: Never
      containers:
      - name: wait-client
        image: {{ .Values.kubectlImage }}
        command: ["/bin/sh", "-c"]
        # delete default profile first
        args:
        - |
          kubectl delete profile {{ .Values.dex.defaultUserProfile }}
